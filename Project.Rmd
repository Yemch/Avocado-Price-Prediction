---
title: "Descriptive analysis (2015-2018) and prediction of avocado prices in the United States in 2017"
author: "Mingchen Ye, Monica Deng, Nazleen Khan"
date: "12/12/2020"
output: html_document
---

# Project Introduction

## Overview and Motivation

The US demand for avocados has increased substantially since the 1980s (Carman HF, 2018). As a healthy superfood, avocados can be easily incorporated into several meals to meet the requirements for daily intake of fiber, potassium, and monounsaturated fatty acids (Carman HF, 2018). If high demand for avocados leads to more competitive pricing, individuals in certain areas may not be able to incorporate avocados into their diets. We propose a US county-level descriptive analysis of avocado prices in comparison with food environment characteristics from 2015 to 2018. 

We also use these and related variables to predict avocado prices in 2017 across 28 US counties with a diverse range of food environments. Our goal is to use Random Forest algorithm to (1) provide context for area-specific food choices and (2) offer information on locations where avocados may be more reasonably priced.

Our project will:

- describe avocado prices and volumes across different US counties and over time (2015-2018).
- predict avocado prices using variables such as race percentage, median household income, access and proximity to grocery stores, and food purchasing assistance across 28 US counties in 2017.

## Related Work

We were motivated to investigate this research question based upon our personal consumption patterns of avocados. Since these superfoods are easily incorporated into any meal, we often find limited availability at local grocery stores and substantial variation in prices. An exploratory analysis of county-level price and volume changes over time and factors that may predict cost are imperative to identify food environments where avocados may be more affordable.    

## Initial Questions

The questions we considered in our project include the following:

- How do avocado price and volume change over time across different regions of the US?

We initially intended to answer this question given our personal motivations to understand geographic variation in avocado pricing. However, our dataset only captured avocado price and volume for a limited set of US counties from 2015-2018. Our research question then evolved to investigating changes in avocado price and volume for select counties with a diverse range of food environments and for a specific calendar date range. Additional analyses may be needed to determine whether our results can be extrapolated to other locations and time periods. 

- What are the most important predictors of avocado price across the different locations?

We were interested in evaluating this question to identify locations where avocados may be more reasonably priced. The Food Environment Atlas seemed to provide the most information on likely predictors of avocado price at the county level, such as median household income and proximity to local grocery stores. However, these variables were ranked of lower importance compared to factors such as total bags and numbers of avocados sold. Future studies may seek to incorporate data from other sources to more accurately predict avocado price across the United States.

- Given the limitations of any dataset, what are additional variables that would be useful to incorporate in the machine learning algorithm to improve prediction?

Although the Food Environment Atlas contained information on over 250 variables related to socioeconomic characteristics, these factors had limited predictive ability in the machine learning algorithm. Many of the variables were also strongly correlated such that the number of unique predictors decreased from 280 to 45. Additional variables that were not captured and may be useful to investigate in future iterations of this analysis include avocado brand, source (imported or homegrown), and supply shortages. 

- How transportable is the prediction model for outputting expected avocado prices in (1) different locations and (2) varying time periods outside the range of our data?

Our prediction model was derived using data through 2017, so the results are not expected to apply to avocado prices in 2020 (with the COVID-19 pandemic, preliminary studies suggest that grocery prices have risen sharply due to disruption in the food supply chain). We are also cautious to extrapolate our findings to counties that did not contribute data to the machine learning algorithm. Although our initial goal was to predict avocado price across different regions of the US, we acknowledge the limitations of our data and may pursue additional analyses to evaluate transportability.

## Data 

The avocado volumes and prices data from 2015-2018 are collected from Kaggle, which is compiled from the Hass Avocado Board website and includes these variables across different metropolitan areas of the United States. We downloaded these data in .csv format directly and combined them with a Food Environment Atlas dataset with 280 variables related to the food environment and socioeconomic characteristics of all US counties from 2010-2018 from the US Department of Agriculture website. The data can be downloaded in .xls format. The following links reference the data sources:

https://www.kaggle.com/neuromusic/avocado-prices

https://www.ers.usda.gov/data-products/food-environment-atlas/data-access-and-documentation-downloads/

The merging of these datasets required us to make assumptions about the geographic unit of interest. The Kaggle dataset included price and volume data on the city or state level, while the Food Environment Atlas captured potential predictors on the county level. To retain the large number of initial predictors, we transformed the city-level data in the Kaggle dataset to the associated county when possible and merged the datasets by this variable. If the Kaggle dataset included (1) state-level information or (2) combined information for two cities that were 30 miles apart or more, we excluded these observations since we would not be able to merge them with the county-level dataset. This led to 28 counties for which we conducted descriptive analyses and 28 counties from which we predicted avocado price. 

## Exploratory Analysis

We conducted several preliminary analyses to explore the Kaggle dataset. As examples, we plotted trends in avocado price and total volume over time (2015-2018) across several US counties using line graphs and specific price and volume amounts for all counties on a given date with bar charts. These analyses were incorporated into the first tab of the Shiny app.

Our second goal of the project was to apply a machine learning algorithm to predict avocado prices. We intended to restrict prediction to a single year in the Kaggle dataset since we could not accurately capture year-to-year variation in prices due to inflation or supply shortages with the available predictor variables. The Kaggle dataset only contained data on avocado price for the first few months of 2018, so we used cost and volume information for all available counties in 2017 to derive our prediction model. We restricted to variables in the Food Environment Atlas that were captured between 2010 and 2017 to maintain temporality between potential predictor variables and outcome prediction in 2017.  

Our next challenges were to evaluate missing data and correlation between predictors in the merged dataset. Although we considered multiple imputation to address missingness, variables with missing values affected > 25% of the observations. The pattern of missingness also appeared to be missing not at random (MNAR), which is difficult to address with any empirical approach. We conducted an evaluation of all possible predictors and excluded those that with substantial missingness (> 25% observations). We also did not conduct avocado price prediction for Roanoke or St. Louis counties, as both locations had missingness across several important predictors that were retained in the analysis.

We were initially interested in using least absolute shrinkage and selection operator (LASSO) regression to identify important predictors of interest. However, many of the identified variables were strongly correlated (Pearson correlation coefficient ~ 0.99) such that more complex machine learning methods may be warranted to address this issue. We further pruned our list of potential predictors to 45 variables of interest that were not expected to be strongly correlated; for example, we excluded variables for county-level race and ethnicity in 2010 since these measures were also available for 2015. After finalizing our list, we opted for Random Forest regression to output predicted avocado prices.

## Final Analysis

### Descriptive Analysis (Analysis 1)

We depicted trends in avocado average price and total volume over time (2015-2018) across 28 US counties and compared them between counties for a given date. These results are available in the "Basic" tab of the Shiny app. 

Users can plot changes in average price or total volume of two types of avocados (conventional and organic) across time (2015-2018) for a specific county. The bar plots are designed to show the average price or total volume of two types of avocados (conventional and organic) for the 28 US counties with available data on a specific date.

### Avocado Price Prediction by Machine Learning: Random Forest (Analysis 2)

*Methods*

We chose Random Forest regression to predict county-level avocado price in 2017. Random Forest is an extension of regression trees, which predict an outcome variable by partitioning the predictor space and estimating the mean (predicted) outcome within each partition. Rather than constructing a single decision tree, Random Forest incorporates repeated sampling with replacement of the data (bootstrapping) to construct multiple decision trees that are averaged across each other. One benefit of Random Forest is its ability to handle large datasets with higher dimensionality. For our purposes, it also "injects" randomness into the machine learning algorithm to help improve prediction accuracy in the setting of strongly correlated predictors. This methodology improves prediction performance and model stability at the cost of reduced interpretability. 

We first restricted the avocado volume data to 2017 to maintain temporality between predictor variables captured between 2010-2017 and the outcome of interest. From the 305 potential predictors, we excluded those with > 25% missingness and/or strong collinearity based on subject matter knowledge. There were 2,968 observations and 45 predictors remaining in the dataset, including race percentage, median household income, poverty rate, and total number of avocados sold, etc. After excluding Roanoke and St. Louis counties, there were no missing values across any of the 28 counties. 

We randomly split the data into training and testing datasets using a 70:30 ratio, resulting in 2,064 observations and 904 observations, respectively. In the training dataset, we performed Random Forest regression by constructing 500 regression trees and averaging them across each other (see code below for more details). We specified that the model randomly sample 15 variables as candidates at each data partition (number of predictors/3 = 45/3) to reduce correlation between the multiple regression trees. We also required that each terminal node contain at least 100 observations to calculate the mean (predicted) outcome. This algorithm was later applied to the testing dataset to evaluate model performance based on several metrics. We compared the mean squared error (MSE), Pearson correlation coefficients, and the plots of observed against predicted avocado prices in the training and testing datasets. Due to the limited interpretability of Random Forest, the most important predictors across the regression trees were identified by the associated Gini score. This metric is used to evaluate variable importance in Random Forest regression, with a higher score reflecting greater importance of the variable in predicting the outcome.  

*Results*

A low MSE (close to 0) and high Pearson correlation coefficient (close to -1 or +1) indicate optimal model performance. The MSE in the test dataset (0.072) was slightly higher than that in the training set (0.066), which is expected since most prediction models perform optimally in the training datasets from which they are derived. Due to the small difference in MSE between the training and test datasets and methodology of the Random Forest, there is little concern for overfitting. Overall, the MSE in the test dataset is small and Pearson correlation coefficient is high (0.818), which suggests that the model performs fairly well in predicting county-level avocado price. The two plots of observed versus predicted avocado prices demonstrate the performance of the Random Forest model in both training and test datasets. The closer the points are to the diagonal reference line, the better the observed and predicted prices align with each other. In both plots, the points gather around the line. Overall, our prediction model indicates little risk of overfitting and adequate performance in the testing dataset.

We ranked the top 10 predictors in descending order of Gini scores. Based on this plot, the total number of bags of avocados sold (Total.Bags) is the most important predictor of county-level avocado price in the Random Forest regression model. The total volume of avocados sold (Total.Volume) and the type of avocado (organic or conventional) came in second and third place, respectively. The model performance results are displayed in the tab “Model Performance” in the Shiny app.

*Limitations*

Our prediction algorithm has limitations. We only used data up to and including 2017, so we could not capture yearly or seasonal variation in avocado price as potential predictors. Our predictions may not be generalizable to counties outside of the 28 studied if they have different characteristics compared with these 28 counties. Several variables were excluded due to missingness and/or strong correlation; future studies may incorporate data from several sources with a diverse range of potential predictors to more accurately predict avocado prices across the United States.

### Shiny App (Analysis 3)

We displayed our main results and visualizations in all four tabs of the Shiny app, including the plots of exploratory analyses, prediction performance, information on important predictors, results of the prediction, and overall project information. Moreover, the app is made to be interactive so that the users can input values for the most important predictors and check the results. In this part, we will mainly describe the layouts and functions of the app. Technical details and interpretations have been explained in the previous parts of Analysis 1 and 2.

The first tab of the Shiny app focuses on descriptive analyses, including basic plots of average prices and total volumes of avocados by US county. 

The second tab contains information on the performance of the Random Forest regression model used to predict avocado prices across 28 US counties with county-level data in 2017. The tab also presents the distribution of the top 10 most important variables used for avocado price prediction based on the associated Gini scores. The box on the top left illustrates the performance statistics of the Random Forest model, including the MSE and Pearson correlation coefficient between observed and predicted avocado prices in both training and test datasets. The plot "Top 10 Important Predictors Identified by Random Forest" ranks the top 10 predictors in descending order of Gini score. Below that, there are the two plots of observed versus predicted avocado prices in both training and test datasets. At the bottom, users can select a variable among the top 10 important predictors, and the associated table outputs basic information on the selected variable. The plot on the right-hand side shows the density plot of the predictor.

The third tab applies the results of the Random Forest regression model to US county-level avocado price prediction. Users can input the values of the top 10 most important predictors (other predictors were set to median values in the code) and press the button "Predict Now", which outputs the predicted price for one avocado in the blue box. Below the blue box, users can select up to six counties. The box plot for each county shows the distribution of predicted avocado price, which can help users identify locations where avocados may be more affordable on average. Additional information is printed below the box plots, such as the associated state for each county, median predicted avocado price, and interquartile range of predicted avocado price.

The fourth tab contains overall information on the project, including background and motivation, data sources, and key references.

## Websites

Project website: https://sites.google.com/view/avocadopriceprediction/home

GitHub repository: https://github.com/Yemch/Avocado-Price-Prediction

Screencast: https://youtu.be/6C_0NpOehkU

## References:

Carman HF. (2018). The story behind avocados’ rise to prominence in the United States. Giannini Foundation of Agricultural Economics, University of California. Accessed 11/01/2020 at https://s.giannini.ucop.edu/uploads/giannini_public/5c/1f/5c1fa9d0-c5c9-45ce-8606-149ddf4f7397/v22n5_3.pdf.

US Department of Agriculture. (2020). US avocado demand is climbing steadily. Accessed 11/01/2020 at https://www.ers.usda.gov/data-products/chart-gallery/gallery/chart-detail/?chartId=98071.




---------------------


---------------------


# Data Wrangling

This part is for the data wrangling process. We first cleaned the `avocado.csv` with unclear region descriptions and restricted the data only at city level. Since avocado prices data is mainly at city level and the Food Environment Atlas datasets are at county level, we created a new dataset `Cities-Counties-States.xlsx` manually for linking the cities to counties. After that, we merged prices data and food environment data together by the same county in the same state. Finally, a cleaned version of data is outputted as `avocado_clean.csv` for downstream analyses.


```{r}
library(tidyverse)
library(readxl)
library(purrr)
```

### 1. Avocado Prices Data Cleaning
Historical data on avocado prices and sales volume in multiple US markets.
This data contains the outcome - the average price of a single avocado. The prices are summarized at the city level.
Source: https://www.kaggle.com/neuromusic/avocado-prices

Some relevant columns in the dataset:

Date - The date of the observation  

AveragePrice - the average price of a single avocado  

type - conventional or organic  

year - the year  

Region - the city or region of the observation  

Total Volume - Total number of avocados sold  

4046 - Total number of avocados with PLU 4046 sold  

4225 - Total number of avocados with PLU 4225 sold  

4770 - Total number of avocados with PLU 4770 sold  


```{r}
avocado = read.csv("./avocado.csv") # avocado price data
city2county = read_xlsx("./Cities-Counties-States.xlsx") # city to county mapping data
head(avocado)
```

```{r}
summary(avocado)
```

Keep data with regions at the city level. For regions of combination of two cities such as "BaltimoreWashington", we exclude if two cities have distance greater than 30 miles, because we assume that cities with equal or closer distance of 30 miles have the same avocado prices.
```{r}
# Check all the combined cities left
city2county %>% 
  filter(Include == 1) %>%
  filter(!is.na(County2)) 

# Make a new dataset with separate cities
com = data.frame(Location = c("Hartford","Springfield","Miami","Fort Lauderdale"),
                 County1= c("HARTFORD","HAMPDEN","MIAMI-DADE","BROWARD"),
                 County2= NA,
                 Distance = NA,
                 State = c("CONNECTICUT","MASSACHUSETTS","FLORIDA","FLORIDA"))
com

# Drop not useful regions broader than city level (set Include == 1)
# Remove the rows with combination cities
# Add cities back separately
# remove unuseful columns
city2county = city2county %>%
  filter(Include == 1) %>%
  filter(Location != "HartfordSpringfield") %>%
  filter(Location != "MiamiFtLauderdale") %>%
  bind_rows(com) %>%
  dplyr::select(-County2,-Distance)

# Combine price dataset and county data together
avocado = avocado %>% 
  left_join(city2county, by = c("region" = "Location")) %>%
  filter(Include == 1) %>%
  dplyr::select(-X,-Include) # remove the first column

```

### 2. Food Environment Atlas Data Cleaning

These data are the potential predictors to be used in prediction analysis.

Load food environment atlas data. 
```{r}
county = read_xlsx("./FoodAtlasData/County.xlsx")
state = read_xlsx("./FoodAtlasData/State.xlsx")
access = read_xlsx("./FoodAtlasData/Access.xlsx")
stores = read_xlsx("./FoodAtlasData/Stores.xlsx")
restaurants = read_xlsx("./FoodAtlasData/Restaurants.xlsx")
assistance = read_xlsx("./FoodAtlasData/Assistance.xlsx")
insecurity = read_xlsx("./FoodAtlasData/Insecurity.xlsx")
taxes = read_xlsx("./FoodAtlasData/Taxes.xlsx")
local = read_xlsx("./FoodAtlasData/Local.xlsx")
health = read_xlsx("./FoodAtlasData/Health.xlsx")
socioecon = read_xlsx("./FoodAtlasData/SocioEconomic.xlsx")

# remove the last row in local dataset, which is an NA row 
local = local[1:nrow(local)-1,]
```

Merge all food environment atlas data together except for state population
```{r}
# Combine food environment atlas covariates together (county-level)
foodatlas = 
  # Place all tables at county-level into a list
  list(county, access, stores, restaurants, assistance, insecurity, taxes, local, health, socioecon) %>% 
  # Use reduce to join together the contents of the list
  reduce(left_join, by = "FIPS")

# Uncomment this line to check number of NA in each column
# apply(foodatlas, 2, function(x){sum(is.na(x))})

# remove duplicate columns
foodatlas = foodatlas %>% 
  dplyr::select(-State.x.x, -State.x.x.x, -State.x.x.x.x, -State.x.x.x.x.x, -State.y, -State.y.y, -State.y.y.y, -State.y.y.y.y, -State.y.y.y.y.y,
                -County.x.x, -County.x.x.x, -County.x.x.x.x, -County.x.x.x.x.x, -County.x, -County.y.y, -County.y.y.y, -County.y.y.y.y, -County.y.y.y.y.y)
```

### 3. Merge two parts together
```{r}
# Capitalize all the Counties and States in food environment atlas data
foodatlas$State.x = toupper(foodatlas$State.x)
foodatlas$County.y = toupper(foodatlas$County.y)

avocado = avocado %>%
  left_join(foodatlas, by = c("County1" = "County.y", "State" = "State.x"))

avocado = rename(avocado, County = County1)
avocado$County = tolower(avocado$County)
dim(avocado)
```

Output a cleaned version of avocado data:
```{r}
write.csv(avocado,"./avocado_clean.csv", row.names = F)
```


-------------

-------------

# Price Prediction by Machine Learning: Random Forest

## Loading necessary packages
```{r}
library(tidyverse)
library(gamlr)
library(Matrix)
library(lubridate)
library(randomForest)
library(MASS)
library(knitr)
library(caTools)
```

## Pulling in the wrangled data and creating the training and testing datasets
```{r}
avocado_clean <- read.csv("avocado_clean.csv") # 10,140 observations of 306 variables
avocado_2017 <- avocado_clean %>%
                filter(year == 2017 & County != "roanoke" & County != "stlouis") %>% 
                dplyr::select(c("AveragePrice", "Total.Volume", "Total.Bags", "type",
                                   "County", "Population_Estimate_2016", "PCT_LACCESS_POP15",
                                   "GROCPTH16", "SUPERCPTH16", "CONVSPTH16", "SPECSPTH16",
                                   "SNAPSPTH12", "WICSPTH16", "FFRPTH16", "FSRPTH16", 
                                   "PC_FFRSALES12", "PC_FSRSALES12",
                                   "SODATAX_STORES14", "SODATAX_VENDM14", "CHIPSTAX_STORES14",
                                   "CHIPSTAX_VENDM14", "PCH_FDPIR_12_15", "FOOD_TAX14", "METRO13",
                                   "DIRSALES_FARMS12", "VEG_FARMS12", "ORCHARD_FARMS12",
                                   "BERRY_FARMS12", "SLHOUSE12", "GHVEG_FARMS12", "CSA12",
                                   "AGRITRSM_OPS12","FARM_TO_SCHOOL15", "PCT_DIABETES_ADULTS13",
                                   "RECFACPTH16", "PCT_NHWHITE10", "PCT_NHBLACK10", "PCT_HISP10",
                                   "PCT_NHASIAN10", "PCT_NHNA10", "PCT_NHPI10", "PCT_65OLDER10",
                                   "PCT_18YOUNGER10", "MEDHHINC15", "POVRATE15", "POPLOSS10"))
# Exclude Roanoke county and St. Louis because they have missing values across several important predictors
# Train and test prediction model using 2017 observations 
# 2,968 observations of 46 variables 
# Pre-selected variables without substantial missingness or correlation from subject matter knowledge
set.seed(610)
sample = sample.split(avocado_2017, SplitRatio = 0.70)
train = subset(avocado_2017, sample == TRUE)
test = subset(avocado_2017, sample == FALSE) 
# Randomly split 2017 data into 70:30 training and testing datasets
```

## Assessing the missingness
```{r}
## TRAINING DATASET 
sapply(train, function(x) sum(is.na(x))) 
# Number missing by column
sum(is.na(train)) 
# 0 missing observations in training dataset

## TESTING DATASET 
sum(is.na(test)) 
# 0 missing observations in testing dataset
xTest <- test %>% dplyr::select(-AveragePrice) 
# Retain all predictors and exclude outcome variable
```

## Running the random forest in training dataset
```{r}
set.seed(1500)  
train.model.us <- randomForest(AveragePrice ~ ., data = train, mtry = 15, nodesize = 100) 
# p/3 = 45 predictors/3 = 15 variables tried at each split
# mtry reduces correlation between trees and improves accuracy
# nodesize refers to the minimum number of observations at each split
train.model.us
```

## Evaluating random forest performance in training and testing datasets
```{r}
pred.train = predict(train.model.us, newdata = train)
head(pred.train)
train %>% ggplot() +
          geom_point(aes(x = pred.train, y = AveragePrice), color = "green") +
          geom_abline(slope = 1) + 
          scale_x_continuous(breaks = seq(0, 2.50, 0.25)) + 
          scale_y_continuous(breaks = seq(0, 3.25, 0.25)) + 
          xlab("Predicted avocado price in the US 2017 training data (US dollars)") + 
          ylab("Observed avocado price in the US 2017 training data (US dollars)") + 
          ggtitle("Observed versus predicted avocado prices in the US 2017 training data")
# Observed vs. predicted values in 2017 US training dataset 

mean((pred.train - train$AveragePrice)^2) 
# MSE = 0.066 in 2017 training dataset
cor.test(as.numeric(pred.train), train$AveragePrice, method = "pearson", conf.level = 0.95)
# Pearson correlation coefficient = 0.834

pred.test = predict(train.model.us, newdata = xTest)
head(pred.test)
xTest %>% ggplot() +
          geom_point(aes(x = pred.test, y = test$AveragePrice), color = "orange") +
          geom_abline(slope = 1) + 
          scale_x_continuous(breaks = seq(0, 2.50, 0.25)) + 
          scale_y_continuous(breaks = seq(0, 3.25, 0.25)) + 
          xlab("Predicted avocado price in the US 2017 testing data (US dollars)") + 
          ylab("Observed avocado price in the US 2017 testing data (US dollars)") + 
          ggtitle("Observed versus predicted avocado prices in the US 2017 testing data")
# Observed vs. predicted values in 2017 testing dataset 

mean((pred.test - test$AveragePrice)^2) 
# MSE = 0.072 in 2017 testing dataset
cor.test(as.numeric(pred.test), test$AveragePrice, method = "pearson", conf.level = 0.95)
# Pearson correlation coefficient = 0.818
```

## Identifying important predictors
```{r}
variable_importance <- importance(train.model.us) 
tmp <- tibble(feature = rownames(variable_importance),
                  Gini = variable_importance[,1]) %>%
                  arrange(desc(Gini))
kable(tmp[1:10,])

tmp %>% filter(Gini > 4.68) %>%
        ggplot(aes(x = reorder(feature, Gini), y = Gini)) +
        geom_bar(stat = 'identity') +
        coord_flip() + xlab("Predictor") +
        theme(axis.text = element_text(size = 8))
```

## Distributions of avocado price predictions in the US in 2017 by county
```{r}
avocado_2017_full <- avocado_clean %>%
                     filter(year == 2017 & County != "roanoke" & County != "stlouis") %>% 
                     dplyr::select(-"AveragePrice")
pred.2017 = predict(train.model.us, newdata = avocado_2017_full)
avocado_2017_full %>% ggplot(aes(x = factor(County), y = pred.2017)) + 
                      scale_y_continuous(breaks = seq(0, 2.50, 0.25)) + 
                      xlab("US county") + 
                      ylab("Predicted avocado price (US dollars)") + 
                      ggtitle("Distribution of predicted avocado price across US counties") + 
                      geom_boxplot(fill = "lightblue", alpha = 0.8) + 
                      theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 12),
                      axis.title.y = element_text(size = 12), plot.title =  element_text(size = 12))
```



